{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"from basic_methods.feature_extraction import TfidfTransformer \nfrom sklearn.feature_extraction.text import CountVectorizer \nimport pandas as pd\nimport warnings\nimport numpy as np"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"# 读取数据\ndataset = pd.read_csv('./resources/train.csv',sep=\"\\t\",names=[\"label\",\"comment\"],skiprows=1,encoding='utf-8')\ncomments = dataset['comment'].tolist()"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"Building prefix dict from the default dictionary ...\nLoading model from cache C:\\Users\\lonel\\AppData\\Local\\Temp\\jieba.cache\nLoading model cost 1.171 seconds.\nPrefix dict has been built succesfully.\njieba result:一如既往 地 好吃 ， 希望 可以 开 到 其他 城市\nModel loaded succeed\nthulac result:一如既往 地 好吃 ， 希望 可以 开 到 其他 城市\npkuseg result:一如既往 地 好吃 ， 希望 可以 开到 其他 城市\n"}],"source":"# 使用 jieba、pkuseg、thulac 对首句切词\nimport jieba\nimport pkuseg\nimport thulac\njieba_cuts = jieba.cut(comments[0])\nprint(f\"jieba result:{' '.join(jieba_cuts)}\")\nthu_lac = thulac.thulac(seg_only=True)\nthu_cuts = thu_lac.cut(comments[0], text=True)\nthu_cuts = list(filter(lambda s: not str.isspace(s),thu_cuts.split()))\nprint(f\"thulac result:{' '.join(thu_cuts)}\")\npku_seg = pkuseg.pkuseg()\npku_result = pku_seg.cut(comments[0])\nprint(f\"pkuseg result:{' '.join(pku_result)}\")"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"# 读取停用词并冻结\nwith open('./resources/stop_words_zh_cn.txt', 'r', encoding='utf-8') as f:\n    stopwords = list(map(lambda line:line.rstrip('\\n'),f.readlines()))\nstopwords = frozenset(stopwords)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"# 所有文档切词\ncut_comments = list(map(lambda x: ' '.join(jieba.cut(x)), comments))"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"# 使用 sklearn 的计数器统计词频，并使用自己编写的 tfidf transformer 转换\nwarnings.filterwarnings(\"ignore\")\ncount_vector = CountVectorizer(stop_words=stopwords)\nX_train_counts = count_vector.fit_transform(cut_comments)\nmy_tf_transformer = TfidfTransformer().fit(X_train_counts)\nX_train_tf = my_tf_transformer.transform(X_train_counts)\nfeature_names = count_vector.get_feature_names()"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"龙啸\t9.111828078308406\n龙头\t9.517293186416572\n龙抄手\t9.517293186416572\n龙湖\t8.824146005856626\n龙湾\t9.517293186416572\n龙眼\t9.517293186416572\n龙虾\t9.111828078308406\n龙骨\t9.517293186416572\n龟苓膏\t9.111828078308406\n龟速\t6.185088676241367\n"}],"source":"# 部分 idf 值\nfor idx, word in enumerate(feature_names[-10:]):\n  print(\"{}\\t{}\".format(word, my_tf_transformer.idf_[idx]))"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":"[('打扫', 0.3720893477066808),\n ('阿姨', 0.2808786855211425),\n ('场地', 0.36034160249402514),\n ('服务', 0.13519599086077247),\n ('服务行业', 0.3720893477066808),\n ('古色古香', 0.36034160249402514),\n ('干净', 0.18014118338832386),\n ('环境', 0.13619610275722627),\n ('火爆', 0.33203634035971624),\n ('想象', 0.294618819111222)]"},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":"# 对于第 3 条文档，抽取其关键词\ndoc_idx = 2\nfeature_index = X_train_tf[doc_idx,:].nonzero()[1]\ntfidfs = list(zip([feature_names[x] for x in feature_index],[X_train_tf[doc_idx, x] for x in feature_index]))\nsorted(tfidfs, key=lambda x: x[1],reverse=True)\ntfidfs[0:10]"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"# 每文档的五个特征：子句数，词数，每词次数，每词词频，停用词量"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":"[1, 1, 2, 1, 1, 1, 1, 1, 1, 2]"},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":"# 子句数，展示部分\nimport re\ndef cut_sent(para):\n    para = re.sub('([。！？\\?])([^”’])', r\"\\1\\n\\2\", para)\n    para = re.sub('(\\.{6})([^”’])', r\"\\1\\n\\2\", para)\n    para = re.sub('(\\…{2})([^”’])', r\"\\1\\n\\2\", para)\n    para = re.sub('([。！？\\?][”’])([^，。！？\\?])', r'\\1\\n\\2', para)\n    para = para.rstrip()\n    return para.split(\"\\n\")\nsubsents = list(map(lambda doc: len(list(filter(lambda subsent: not str.isspace(subsent),cut_sent(doc)))),comments))\nsubsents[0:10]"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":"[10, 11, 44, 10, 30, 5, 5, 32, 9, 9]"},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":"# 词数，展示部分\nwordnums = list(map(lambda sent: len(sent.split(' ')),cut_comments))\nwordnums[0:10]"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":"[('龙啸', 0),\n ('龙头', 0),\n ('龙抄手', 0),\n ('龙湖', 0),\n ('龙湾', 0),\n ('龙眼', 0),\n ('龙虾', 0),\n ('龙骨', 0),\n ('龟苓膏', 0),\n ('龟速', 0)]"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":"# 每词次数, 以第三条部分为例\nrow_counts = list(zip(feature_names,X_train_counts.toarray()[doc_idx]))\nrow_counts[-10:]"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":"[('龙啸', 0.0),\n ('龙头', 0.0),\n ('龙抄手', 0.0),\n ('龙湖', 0.0),\n ('龙湾', 0.0),\n ('龙眼', 0.0),\n ('龙虾', 0.0),\n ('龙骨', 0.0),\n ('龟苓膏', 0.0),\n ('龟速', 0.0)]"},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":"# 每词频率，以第三条部分为例\nsum_counts = sum(X_train_counts.toarray()[doc_idx])\nrow_freqs = list(zip(feature_names,X_train_counts.toarray()[doc_idx]/sum_counts))\nrow_freqs[-10:]"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":"[5, 5, 30, 4, 12, 2, 1, 21, 4, 6]"},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":"# 停用词数\nstopword_nums = [len(list(filter(lambda x: x in stopwords, comment.split(' ')))) for comment in cut_comments]\nstopword_nums[0:10]"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":"# 引入斯坦福 nlp\nfrom stanfordcorenlp import StanfordCoreNLP"},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":"sentence = comments[0]"},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":"nlp = StanfordCoreNLP(r'resources/stanford-corenlp-full-2018-10-05', lang='zh')"},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"['一', '如', '既往', '地', '好吃', '，', '希望', '可以', '开到', '其他', '城市']\n"}],"source":"# 分词\nprint(nlp.word_tokenize(sentence))"},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[('一', 'CD'), ('如', 'CS'), ('既往', 'VA'), ('地', 'DEV'), ('好吃', 'VA'), ('，', 'PU'), ('希望', 'VV'), ('可以', 'VV'), ('开到', 'VV'), ('其他', 'DT'), ('城市', 'NN')]\n"}],"source":"# 词性分析\nprint(nlp.pos_tag(sentence))"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[('一', 'NUMBER'), ('如', 'O'), ('既往', 'O'), ('地', 'O'), ('好吃', 'O'), ('，', 'O'), ('希望', 'O'), ('可以', 'O'), ('开到', 'O'), ('其他', 'IDEOLOGY'), ('城市', 'O')]\n"}],"source":"# 命名实体识别\nprint(nlp.ner(sentence))"},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(ROOT\n  (NP\n    (QP (CD 一))\n    (IP\n      (VP\n        (ADVP (CS 如))\n        (VP\n          (VP\n            (DVP\n              (VP (VA 既往))\n              (DEV 地))\n            (VP (VA 好吃)))\n          (PU ，)\n          (VP (VV 希望)\n            (IP\n              (VP (VV 可以)\n                (VP (VV 开到)\n                  (NP\n                    (DP (DT 其他))\n                    (NP (NN 城市))))))))))))\n"}],"source":"# 解析\nprint(nlp.parse(sentence))"},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[('ROOT', 0, 7), ('dep', 5, 1), ('advmod', 5, 2), ('advmod:dvp', 5, 3), ('mark', 3, 4), ('dep', 7, 5), ('punct', 7, 6), ('aux:modal', 9, 8), ('ccomp', 7, 9), ('det', 11, 10), ('dobj', 9, 11)]\n"}],"source":"# 依存句法分析\nprint(nlp.dependency_parse(sentence))"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":"nlp.close()"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}