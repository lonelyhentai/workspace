{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"# SZ160110103_周烨恒_第一次实验\nimport pandas as pd\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import CountVectorizer"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"# 任务1, 读取文件\ndf = pd.read_csv('./resources/SW_EpisodeV.txt',sep=\" \",encoding=\"utf-8\",names=[\"index\",\"character\",\"dialogue\"],skiprows=1)"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>character</th>\n","      <th>dialogue</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>LUKE</td>\n","      <td>Echo Three to Echo Seven. Han, old buddy, do y...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>HAN</td>\n","      <td>Loud and clear, kid. What's up?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>LUKE</td>\n","      <td>Well, I finished my circle. I don't pick up an...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>HAN</td>\n","      <td>There isn't enough life on this ice cube to fi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>LUKE</td>\n","      <td>Right. I'll see you shortly. There's a meteori...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index character                                           dialogue\n","0      1      LUKE  Echo Three to Echo Seven. Han, old buddy, do y...\n","1      2       HAN                    Loud and clear, kid. What's up?\n","2      3      LUKE  Well, I finished my circle. I don't pick up an...\n","3      4       HAN  There isn't enough life on this ice cube to fi...\n","4      5      LUKE  Right. I'll see you shortly. There's a meteori..."]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":"df.head()"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["character\n","HAN         182\n","LUKE        128\n","LEIA        114\n","THREEPIO     92\n","LANDO        61\n","VADER        56\n","YODA         36\n","PIETT        23\n","CREATURE     21\n","BEN          15\n","Name: index, dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":"# 任务2, select character, count(index) from df group by character;\ndf.groupby('character')['index'].count().sort_values(ascending=False).head(10)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["[('the', 222),\n"," ('to', 205),\n"," ('you', 180),\n"," ('I', 175),\n"," ('a', 117),\n"," ('of', 81),\n"," ('is', 68),\n"," ('in', 62),\n"," ('have', 62),\n"," (\"I'm\", 61),\n"," ('be', 60),\n"," ('You', 56),\n"," ('and', 55),\n"," ('for', 53),\n"," (\"don't\", 51),\n"," ('not', 51),\n"," ('are', 50),\n"," ('your', 50),\n"," ('it', 48),\n"," ('my', 40)]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":"# 任务3：简化版，不准确\nword_counter = Counter()\nfor i, record in df.iterrows():\n     word_counter.update(record['dialogue'].split())\nword_counter.most_common(20)"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["[('zone', 1170),\n"," ('zero', 1169),\n"," ('young', 1168),\n"," ('yoda', 1167),\n"," ('yes', 1166),\n"," ('years', 1165),\n"," ('yeah', 1164),\n"," ('wrong', 1163),\n"," ('wouldn', 1162),\n"," ('worth', 1161),\n"," ('worship', 1160),\n"," ('worse', 1159),\n"," ('worry', 1158),\n"," ('worried', 1157),\n"," ('working', 1156),\n"," ('work', 1155),\n"," ('word', 1154),\n"," ('wooly', 1153),\n"," ('wookiee', 1152),\n"," ('wondering', 1151)]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":"# 任务3：使用 counter vectorizer 自带正则分词，加去停词，较准确\nvectorizer = CountVectorizer(min_df=1,stop_words=\"english\")\nx = vectorizer.fit_transform(df[\"dialogue\"].tolist())\nsorted_dict = list(reversed(sorted(vectorizer.vocabulary_.items(),key=lambda x:x[1])))\nsorted_dict[0:20]"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>word</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>323</th>\n","      <td>58</td>\n","      <td>don</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     count word\n","323     58  don"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":"# 任务4: 查找前 5 个角色的第一高频词\nnames = set(df.groupby('character')['index'].count().sort_values(ascending=False).head(5).index.to_list())\nlines = []\nfor i, record in df.iterrows():\n    if record['character'] in names:\n        lines.append(i)\nnew_words_dict = pd.DataFrame(zip(x.toarray()[lines,:].sum(axis=0),vectorizer.get_feature_names()),columns=[\"count\",\"word\"])\nnew_words_dict.sort_values(by=\"count\",ascending=False).head(1)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}