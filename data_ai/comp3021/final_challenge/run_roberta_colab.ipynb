{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_roberta_colab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LtGo4uhdIuT9","colab_type":"code","outputId":"daeef6fe-c202-4b4f-c20d-3615fd9956d3","executionInfo":{"status":"ok","timestamp":1572077002767,"user_tz":-480,"elapsed":2078,"user":{"displayName":"蒙古国海军司令","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAz7KWB8tOXuc5KP6AlK0pNtFm-RDgU7LR1VgQR=s64","userId":"17406439168111607696"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AwNcrfkJQ277","colab_type":"code","outputId":"7ba625d7-9dbf-4815-a3a6-11352cedf1f7","executionInfo":{"status":"ok","timestamp":1572077005411,"user_tz":-480,"elapsed":4702,"user":{"displayName":"蒙古国海军司令","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAz7KWB8tOXuc5KP6AlK0pNtFm-RDgU7LR1VgQR=s64","userId":"17406439168111607696"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!pwd"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ZtM0XojJDgh","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/final_challenge')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aifLZ7c2Ks9L","colab_type":"code","outputId":"9249632d-c37b-45bf-ae48-6dd75e67f6bd","executionInfo":{"status":"ok","timestamp":1572077009783,"user_tz":-480,"elapsed":9018,"user":{"displayName":"蒙古国海军司令","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAz7KWB8tOXuc5KP6AlK0pNtFm-RDgU7LR1VgQR=s64","userId":"17406439168111607696"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!pip install regex"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.8.19)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O-_hr-3VM2wK","colab_type":"code","outputId":"d404a34a-c463-4319-ea11-92686cc6547f","executionInfo":{"status":"ok","timestamp":1572077012321,"user_tz":-480,"elapsed":11539,"user":{"displayName":"蒙古国海军司令","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAz7KWB8tOXuc5KP6AlK0pNtFm-RDgU7LR1VgQR=s64","userId":"17406439168111607696"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["!/opt/bin/nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sat Oct 26 08:03:30 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XqPlvZ1kJriU","colab_type":"code","outputId":"4ce083e6-68d1-49b3-9ffa-a9d7d4d250d7","executionInfo":{"status":"ok","timestamp":1572106854963,"user_tz":-480,"elapsed":217894,"user":{"displayName":"蒙古国海军司令","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAz7KWB8tOXuc5KP6AlK0pNtFm-RDgU7LR1VgQR=s64","userId":"17406439168111607696"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!export CUDA_VISIBLE_DEVICES=0\n","!python run_bert.py \\\n","--model_type bert \\\n","--model_name_or_path chinese_roberta \\\n","--do_train \\\n","--do_eval \\\n","--do_test \\\n","--data_dir ./data/data \\\n","--output_dir ./model_roberta \\\n","--max_seq_length 128 \\\n","--split_num 1 \\\n","--lstm_hidden_size 512 \\\n","--lstm_layers 1 \\\n","--lstm_dropout 0.1 \\\n","--eval_steps 100 \\\n","--per_gpu_train_batch_size 32 \\\n","--gradient_accumulation_steps 4 \\\n","--warmup_steps 0 \\\n","--per_gpu_eval_batch_size 64 \\\n","--learning_rate 1e-5 \\\n","--adam_epsilon 1e-6 \\\n","--weight_decay 0 \\\n","--train_steps 20000"],"execution_count":6,"outputs":[{"output_type":"stream","text":["10/26/2019 08:03:37 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","10/26/2019 08:03:37 - INFO - pytorch_transformers.tokenization_utils -   Model name 'chinese_roberta' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'chinese_roberta' is a path or url to a directory containing tokenizer files.\n","10/26/2019 08:03:37 - INFO - pytorch_transformers.tokenization_utils -   Didn't find file chinese_roberta/added_tokens.json. We won't load it.\n","10/26/2019 08:03:37 - INFO - pytorch_transformers.tokenization_utils -   Didn't find file chinese_roberta/special_tokens_map.json. We won't load it.\n","10/26/2019 08:03:37 - INFO - pytorch_transformers.tokenization_utils -   loading file chinese_roberta/vocab.txt\n","10/26/2019 08:03:37 - INFO - pytorch_transformers.tokenization_utils -   loading file None\n","10/26/2019 08:03:37 - INFO - pytorch_transformers.tokenization_utils -   loading file None\n","10/26/2019 08:03:37 - INFO - pytorch_transformers.modeling_utils -   loading configuration file chinese_roberta/config.json\n","10/26/2019 08:03:37 - INFO - pytorch_transformers.modeling_utils -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 21128\n","}\n","\n","10/26/2019 08:03:37 - INFO - pytorch_transformers.modeling_utils -   loading weights file chinese_roberta/pytorch_model.bin\n","10/26/2019 08:03:51 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['pooling.weight', 'pooling.bias', 'classifier.weight', 'classifier.bias', 'W.0.weight', 'W.0.bias', 'gru.0.weight_ih_l0', 'gru.0.weight_hh_l0', 'gru.0.bias_ih_l0', 'gru.0.bias_hh_l0', 'gru.0.weight_ih_l0_reverse', 'gru.0.weight_hh_l0_reverse', 'gru.0.bias_ih_l0_reverse', 'gru.0.bias_hh_l0_reverse']\n","10/26/2019 08:03:51 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","10/26/2019 08:03:52 - INFO - __main__ -   *** Example ***\n","10/26/2019 08:03:52 - INFO - __main__ -   idx: 0\n","10/26/2019 08:03:52 - INFO - __main__ -   guid: 91d4f882-f707-11e9-a5f2-8ca982fce369\n","10/26/2019 08:03:52 - INFO - __main__ -   tokens: [CLS] [SEP] 唱 歌 蛮 好 听 ， 跟 朋 友 聊 聊 天 真 是 不 错 。 嘻 嘻 ， 下 次 有 机 会 还 会 来 坐 坐 。 挺 放 松 心 情 的 ～ [SEP]\n","10/26/2019 08:03:52 - INFO - __main__ -   input_ids: 101 102 1548 3625 6037 1962 1420 8024 6656 3301 1351 5464 5464 1921 4696 3221 679 7231 511 1677 1677 8024 678 3613 3300 3322 833 6820 833 3341 1777 1777 511 2923 3123 3351 2552 2658 4638 8080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","10/26/2019 08:03:52 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","10/26/2019 08:03:52 - INFO - __main__ -   segment_ids: 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","10/26/2019 08:03:52 - INFO - __main__ -   label: 0\n","10/26/2019 08:03:55 - INFO - __main__ -   ***** Running training *****\n","10/26/2019 08:03:55 - INFO - __main__ -     Num examples = 9000\n","10/26/2019 08:03:55 - INFO - __main__ -     Batch size = 32\n","10/26/2019 08:03:55 - INFO - __main__ -     Num steps = 20000\n","loss 0.203:   2% 399/20000 [08:15<6:54:29,  1.27s/it] 10/26/2019 08:12:11 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 08:12:11 - INFO - __main__ -     global_step = 100\n","10/26/2019 08:12:11 - INFO - __main__ -     train loss = 0.203\n","10/26/2019 08:12:12 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 08:12:12 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 08:12:12 - INFO - __main__ -     Batch size = 64\n","10/26/2019 08:13:46 - INFO - __main__ -     eval_F1 = 0.9480520479999076\n","10/26/2019 08:13:46 - INFO - __main__ -     eval_loss = 0.0796374324709177\n","10/26/2019 08:13:46 - INFO - __main__ -     global_step = 100\n","10/26/2019 08:13:46 - INFO - __main__ -     loss = 0.203\n","================================================================================\n","Best F1 0.9480520479999076\n","Saving Model......\n","================================================================================\n","loss 0.0892:   4% 799/20000 [18:33<6:47:13,  1.27s/it]10/26/2019 08:22:28 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 08:22:28 - INFO - __main__ -     global_step = 200\n","10/26/2019 08:22:28 - INFO - __main__ -     train loss = 0.0892\n","10/26/2019 08:22:29 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 08:22:29 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 08:22:29 - INFO - __main__ -     Batch size = 64\n","10/26/2019 08:24:03 - INFO - __main__ -     eval_F1 = 0.9524172059383327\n","10/26/2019 08:24:03 - INFO - __main__ -     eval_loss = 0.07701269397512078\n","10/26/2019 08:24:03 - INFO - __main__ -     global_step = 200\n","10/26/2019 08:24:03 - INFO - __main__ -     loss = 0.0892\n","================================================================================\n","Best F1 0.9524172059383327\n","Saving Model......\n","================================================================================\n","loss 0.0718:   6% 1199/20000 [28:31<6:40:17,  1.28s/it]10/26/2019 08:32:27 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 08:32:27 - INFO - __main__ -     global_step = 300\n","10/26/2019 08:32:27 - INFO - __main__ -     train loss = 0.0718\n","10/26/2019 08:32:27 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 08:32:27 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 08:32:27 - INFO - __main__ -     Batch size = 64\n","10/26/2019 08:34:01 - INFO - __main__ -     eval_F1 = 0.9559824618817688\n","10/26/2019 08:34:01 - INFO - __main__ -     eval_loss = 0.07208824041299522\n","10/26/2019 08:34:01 - INFO - __main__ -     global_step = 300\n","10/26/2019 08:34:01 - INFO - __main__ -     loss = 0.0718\n","================================================================================\n","Best F1 0.9559824618817688\n","Saving Model......\n","================================================================================\n","loss 0.0702:   8% 1599/20000 [38:29<6:30:23,  1.27s/it]10/26/2019 08:42:25 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 08:42:25 - INFO - __main__ -     global_step = 400\n","10/26/2019 08:42:25 - INFO - __main__ -     train loss = 0.0702\n","10/26/2019 08:42:25 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 08:42:25 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 08:42:25 - INFO - __main__ -     Batch size = 64\n","10/26/2019 08:44:00 - INFO - __main__ -     eval_F1 = 0.9580072532926132\n","10/26/2019 08:44:00 - INFO - __main__ -     eval_loss = 0.06760002649389207\n","10/26/2019 08:44:00 - INFO - __main__ -     global_step = 400\n","10/26/2019 08:44:00 - INFO - __main__ -     loss = 0.0702\n","================================================================================\n","Best F1 0.9580072532926132\n","Saving Model......\n","================================================================================\n","loss 0.0487:  10% 1999/20000 [48:29<6:23:21,  1.28s/it]10/26/2019 08:52:25 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 08:52:25 - INFO - __main__ -     global_step = 500\n","10/26/2019 08:52:25 - INFO - __main__ -     train loss = 0.0487\n","10/26/2019 08:52:25 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 08:52:25 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 08:52:25 - INFO - __main__ -     Batch size = 64\n","10/26/2019 08:53:59 - INFO - __main__ -     eval_F1 = 0.9654600718430506\n","10/26/2019 08:53:59 - INFO - __main__ -     eval_loss = 0.059646077861543745\n","10/26/2019 08:53:59 - INFO - __main__ -     global_step = 500\n","10/26/2019 08:53:59 - INFO - __main__ -     loss = 0.0487\n","================================================================================\n","Best F1 0.9654600718430506\n","Saving Model......\n","================================================================================\n","loss 0.0419:  12% 2399/20000 [58:27<6:13:53,  1.27s/it]10/26/2019 09:02:23 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 09:02:23 - INFO - __main__ -     global_step = 600\n","10/26/2019 09:02:23 - INFO - __main__ -     train loss = 0.0419\n","10/26/2019 09:02:24 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 09:02:24 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 09:02:24 - INFO - __main__ -     Batch size = 64\n","10/26/2019 09:03:58 - INFO - __main__ -     eval_F1 = 0.9464619667658044\n","10/26/2019 09:03:58 - INFO - __main__ -     eval_loss = 0.07916062558069825\n","10/26/2019 09:03:58 - INFO - __main__ -     global_step = 600\n","10/26/2019 09:03:58 - INFO - __main__ -     loss = 0.0419\n","================================================================================\n","loss 0.0402:  14% 2799/20000 [1:08:21<6:08:07,  1.28s/it]10/26/2019 09:12:17 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 09:12:17 - INFO - __main__ -     global_step = 700\n","10/26/2019 09:12:17 - INFO - __main__ -     train loss = 0.0402\n","10/26/2019 09:12:17 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 09:12:17 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 09:12:17 - INFO - __main__ -     Batch size = 64\n","10/26/2019 09:13:52 - INFO - __main__ -     eval_F1 = 0.9343564009802777\n","10/26/2019 09:13:52 - INFO - __main__ -     eval_loss = 0.11569170106668025\n","10/26/2019 09:13:52 - INFO - __main__ -     global_step = 700\n","10/26/2019 09:13:52 - INFO - __main__ -     loss = 0.0402\n","================================================================================\n","loss 0.0202:  16% 3199/20000 [1:18:17<5:59:27,  1.28s/it]10/26/2019 09:22:13 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 09:22:13 - INFO - __main__ -     global_step = 800\n","10/26/2019 09:22:13 - INFO - __main__ -     train loss = 0.0202\n","10/26/2019 09:22:13 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 09:22:13 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 09:22:13 - INFO - __main__ -     Batch size = 64\n","10/26/2019 09:23:48 - INFO - __main__ -     eval_F1 = 0.9390774104576394\n","10/26/2019 09:23:48 - INFO - __main__ -     eval_loss = 0.12500921613536775\n","10/26/2019 09:23:48 - INFO - __main__ -     global_step = 800\n","10/26/2019 09:23:48 - INFO - __main__ -     loss = 0.0202\n","================================================================================\n","loss 0.0271:  18% 3599/20000 [1:28:11<5:47:48,  1.27s/it]10/26/2019 09:32:07 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 09:32:07 - INFO - __main__ -     global_step = 900\n","10/26/2019 09:32:07 - INFO - __main__ -     train loss = 0.0271\n","10/26/2019 09:32:07 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 09:32:07 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 09:32:07 - INFO - __main__ -     Batch size = 64\n","10/26/2019 09:33:41 - INFO - __main__ -     eval_F1 = 0.9350599952872112\n","10/26/2019 09:33:41 - INFO - __main__ -     eval_loss = 0.11638536333339289\n","10/26/2019 09:33:41 - INFO - __main__ -     global_step = 900\n","10/26/2019 09:33:41 - INFO - __main__ -     loss = 0.0271\n","================================================================================\n","loss 0.018:  20% 3999/20000 [1:38:03<5:40:18,  1.28s/it]10/26/2019 09:41:59 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 09:41:59 - INFO - __main__ -     global_step = 1000\n","10/26/2019 09:41:59 - INFO - __main__ -     train loss = 0.018\n","10/26/2019 09:41:59 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 09:41:59 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 09:41:59 - INFO - __main__ -     Batch size = 64\n","10/26/2019 09:43:34 - INFO - __main__ -     eval_F1 = 0.940173049454453\n","10/26/2019 09:43:34 - INFO - __main__ -     eval_loss = 0.14112116413889453\n","10/26/2019 09:43:34 - INFO - __main__ -     global_step = 1000\n","10/26/2019 09:43:34 - INFO - __main__ -     loss = 0.018\n","================================================================================\n","loss 0.0188:  22% 4399/20000 [1:47:56<5:32:01,  1.28s/it]10/26/2019 09:51:52 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 09:51:52 - INFO - __main__ -     global_step = 1100\n","10/26/2019 09:51:52 - INFO - __main__ -     train loss = 0.0188\n","10/26/2019 09:51:52 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 09:51:52 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 09:51:52 - INFO - __main__ -     Batch size = 64\n","10/26/2019 09:53:26 - INFO - __main__ -     eval_F1 = 0.9491309877066554\n","10/26/2019 09:53:26 - INFO - __main__ -     eval_loss = 0.12109996867366135\n","10/26/2019 09:53:26 - INFO - __main__ -     global_step = 1100\n","10/26/2019 09:53:26 - INFO - __main__ -     loss = 0.0188\n","================================================================================\n","loss 0.0209:  24% 4799/20000 [1:57:48<5:22:28,  1.27s/it]10/26/2019 10:01:44 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 10:01:44 - INFO - __main__ -     global_step = 1200\n","10/26/2019 10:01:44 - INFO - __main__ -     train loss = 0.0209\n","10/26/2019 10:01:44 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 10:01:44 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 10:01:44 - INFO - __main__ -     Batch size = 64\n","10/26/2019 10:03:19 - INFO - __main__ -     eval_F1 = 0.9564419513248275\n","10/26/2019 10:03:19 - INFO - __main__ -     eval_loss = 0.09725096600595862\n","10/26/2019 10:03:19 - INFO - __main__ -     global_step = 1200\n","10/26/2019 10:03:19 - INFO - __main__ -     loss = 0.0209\n","================================================================================\n","loss 0.0205:  26% 5199/20000 [2:07:40<5:14:00,  1.27s/it]10/26/2019 10:11:36 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 10:11:36 - INFO - __main__ -     global_step = 1300\n","10/26/2019 10:11:36 - INFO - __main__ -     train loss = 0.0205\n","10/26/2019 10:11:36 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 10:11:36 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 10:11:36 - INFO - __main__ -     Batch size = 64\n","10/26/2019 10:13:10 - INFO - __main__ -     eval_F1 = 0.954429456799125\n","10/26/2019 10:13:10 - INFO - __main__ -     eval_loss = 0.10412774590076879\n","10/26/2019 10:13:10 - INFO - __main__ -     global_step = 1300\n","10/26/2019 10:13:10 - INFO - __main__ -     loss = 0.0205\n","================================================================================\n","loss 0.0107:  28% 5599/20000 [2:17:32<5:05:20,  1.27s/it]10/26/2019 10:21:28 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 10:21:28 - INFO - __main__ -     global_step = 1400\n","10/26/2019 10:21:28 - INFO - __main__ -     train loss = 0.0107\n","10/26/2019 10:21:28 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 10:21:28 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 10:21:28 - INFO - __main__ -     Batch size = 64\n","10/26/2019 10:23:02 - INFO - __main__ -     eval_F1 = 0.9602296077313643\n","10/26/2019 10:23:02 - INFO - __main__ -     eval_loss = 0.11852368107065558\n","10/26/2019 10:23:02 - INFO - __main__ -     global_step = 1400\n","10/26/2019 10:23:02 - INFO - __main__ -     loss = 0.0107\n","================================================================================\n","loss 0.0171:  30% 5999/20000 [2:27:23<4:56:44,  1.27s/it]10/26/2019 10:31:19 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 10:31:19 - INFO - __main__ -     global_step = 1500\n","10/26/2019 10:31:19 - INFO - __main__ -     train loss = 0.0171\n","10/26/2019 10:31:20 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 10:31:20 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 10:31:20 - INFO - __main__ -     Batch size = 64\n","10/26/2019 10:32:54 - INFO - __main__ -     eval_F1 = 0.9508881685820281\n","10/26/2019 10:32:54 - INFO - __main__ -     eval_loss = 0.11368876975029707\n","10/26/2019 10:32:54 - INFO - __main__ -     global_step = 1500\n","10/26/2019 10:32:54 - INFO - __main__ -     loss = 0.0171\n","================================================================================\n","loss 0.0041:  32% 6399/20000 [2:37:15<4:47:53,  1.27s/it]10/26/2019 10:41:11 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 10:41:11 - INFO - __main__ -     global_step = 1600\n","10/26/2019 10:41:11 - INFO - __main__ -     train loss = 0.0041\n","10/26/2019 10:41:11 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 10:41:11 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 10:41:11 - INFO - __main__ -     Batch size = 64\n","10/26/2019 10:42:46 - INFO - __main__ -     eval_F1 = 0.9473826633392465\n","10/26/2019 10:42:46 - INFO - __main__ -     eval_loss = 0.15122856723610312\n","10/26/2019 10:42:46 - INFO - __main__ -     global_step = 1600\n","10/26/2019 10:42:46 - INFO - __main__ -     loss = 0.0041\n","================================================================================\n","loss 0.0122:  34% 6799/20000 [2:47:07<4:40:04,  1.27s/it]10/26/2019 10:51:03 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 10:51:03 - INFO - __main__ -     global_step = 1700\n","10/26/2019 10:51:03 - INFO - __main__ -     train loss = 0.0122\n","10/26/2019 10:51:04 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 10:51:04 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 10:51:04 - INFO - __main__ -     Batch size = 64\n","10/26/2019 10:52:38 - INFO - __main__ -     eval_F1 = 0.9528990626913475\n","10/26/2019 10:52:38 - INFO - __main__ -     eval_loss = 0.12824645591899753\n","10/26/2019 10:52:38 - INFO - __main__ -     global_step = 1700\n","10/26/2019 10:52:38 - INFO - __main__ -     loss = 0.0122\n","================================================================================\n","loss 0.0139:  36% 7199/20000 [2:57:00<4:31:42,  1.27s/it]10/26/2019 11:00:56 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 11:00:56 - INFO - __main__ -     global_step = 1800\n","10/26/2019 11:00:56 - INFO - __main__ -     train loss = 0.0139\n","10/26/2019 11:00:56 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 11:00:56 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 11:00:56 - INFO - __main__ -     Batch size = 64\n","10/26/2019 11:02:30 - INFO - __main__ -     eval_F1 = 0.9618247757205574\n","10/26/2019 11:02:30 - INFO - __main__ -     eval_loss = 0.1051244362606667\n","10/26/2019 11:02:30 - INFO - __main__ -     global_step = 1800\n","10/26/2019 11:02:30 - INFO - __main__ -     loss = 0.0139\n","================================================================================\n","loss 0.0133:  38% 7599/20000 [3:06:52<4:23:46,  1.28s/it]10/26/2019 11:10:48 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 11:10:48 - INFO - __main__ -     global_step = 1900\n","10/26/2019 11:10:48 - INFO - __main__ -     train loss = 0.0133\n","10/26/2019 11:10:49 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 11:10:49 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 11:10:49 - INFO - __main__ -     Batch size = 64\n","10/26/2019 11:12:23 - INFO - __main__ -     eval_F1 = 0.9524062450621479\n","10/26/2019 11:12:23 - INFO - __main__ -     eval_loss = 0.13816521392436698\n","10/26/2019 11:12:23 - INFO - __main__ -     global_step = 1900\n","10/26/2019 11:12:23 - INFO - __main__ -     loss = 0.0133\n","================================================================================\n","loss 0.008:  40% 7999/20000 [3:16:45<4:14:14,  1.27s/it]10/26/2019 11:20:41 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 11:20:41 - INFO - __main__ -     global_step = 2000\n","10/26/2019 11:20:41 - INFO - __main__ -     train loss = 0.008\n","10/26/2019 11:20:41 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 11:20:41 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 11:20:41 - INFO - __main__ -     Batch size = 64\n","10/26/2019 11:22:15 - INFO - __main__ -     eval_F1 = 0.9459196365799578\n","10/26/2019 11:22:15 - INFO - __main__ -     eval_loss = 0.1602788669988513\n","10/26/2019 11:22:15 - INFO - __main__ -     global_step = 2000\n","10/26/2019 11:22:15 - INFO - __main__ -     loss = 0.008\n","================================================================================\n","loss 0.0121:  42% 8399/20000 [3:26:37<4:06:13,  1.27s/it]10/26/2019 11:30:33 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 11:30:33 - INFO - __main__ -     global_step = 2100\n","10/26/2019 11:30:33 - INFO - __main__ -     train loss = 0.0121\n","10/26/2019 11:30:33 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 11:30:33 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 11:30:33 - INFO - __main__ -     Batch size = 64\n","10/26/2019 11:32:08 - INFO - __main__ -     eval_F1 = 0.9476514182726463\n","10/26/2019 11:32:08 - INFO - __main__ -     eval_loss = 0.12628768314607441\n","10/26/2019 11:32:08 - INFO - __main__ -     global_step = 2100\n","10/26/2019 11:32:08 - INFO - __main__ -     loss = 0.0121\n","================================================================================\n","loss 0.0124:  44% 8799/20000 [3:36:30<3:57:52,  1.27s/it]10/26/2019 11:40:25 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 11:40:25 - INFO - __main__ -     global_step = 2200\n","10/26/2019 11:40:25 - INFO - __main__ -     train loss = 0.0124\n","10/26/2019 11:40:26 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 11:40:26 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 11:40:26 - INFO - __main__ -     Batch size = 64\n","10/26/2019 11:42:00 - INFO - __main__ -     eval_F1 = 0.9323670967753728\n","10/26/2019 11:42:00 - INFO - __main__ -     eval_loss = 0.14395328401587903\n","10/26/2019 11:42:00 - INFO - __main__ -     global_step = 2200\n","10/26/2019 11:42:00 - INFO - __main__ -     loss = 0.0124\n","================================================================================\n","loss 0.0068:  46% 9199/20000 [3:46:19<3:46:51,  1.26s/it]10/26/2019 11:50:15 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 11:50:15 - INFO - __main__ -     global_step = 2300\n","10/26/2019 11:50:15 - INFO - __main__ -     train loss = 0.0068\n","10/26/2019 11:50:16 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 11:50:16 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 11:50:16 - INFO - __main__ -     Batch size = 64\n","10/26/2019 11:51:49 - INFO - __main__ -     eval_F1 = 0.9459196365799578\n","10/26/2019 11:51:49 - INFO - __main__ -     eval_loss = 0.16424422012642026\n","10/26/2019 11:51:49 - INFO - __main__ -     global_step = 2300\n","10/26/2019 11:51:49 - INFO - __main__ -     loss = 0.0068\n","================================================================================\n","loss 0.0087:  48% 9599/20000 [3:56:07<3:39:09,  1.26s/it]10/26/2019 12:00:03 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 12:00:03 - INFO - __main__ -     global_step = 2400\n","10/26/2019 12:00:03 - INFO - __main__ -     train loss = 0.0087\n","10/26/2019 12:00:03 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 12:00:03 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 12:00:03 - INFO - __main__ -     Batch size = 64\n","10/26/2019 12:01:37 - INFO - __main__ -     eval_F1 = 0.9456431076397676\n","10/26/2019 12:01:37 - INFO - __main__ -     eval_loss = 0.1394027171190828\n","10/26/2019 12:01:37 - INFO - __main__ -     global_step = 2400\n","10/26/2019 12:01:37 - INFO - __main__ -     loss = 0.0087\n","================================================================================\n","loss 0.0069:  50% 9999/20000 [4:05:55<3:31:00,  1.27s/it]10/26/2019 12:09:51 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 12:09:51 - INFO - __main__ -     global_step = 2500\n","10/26/2019 12:09:51 - INFO - __main__ -     train loss = 0.0069\n","10/26/2019 12:09:51 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 12:09:51 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 12:09:51 - INFO - __main__ -     Batch size = 64\n","10/26/2019 12:11:24 - INFO - __main__ -     eval_F1 = 0.9333723228629173\n","10/26/2019 12:11:24 - INFO - __main__ -     eval_loss = 0.16926166351186112\n","10/26/2019 12:11:24 - INFO - __main__ -     global_step = 2500\n","10/26/2019 12:11:24 - INFO - __main__ -     loss = 0.0069\n","================================================================================\n","loss 0.0119:  52% 10399/20000 [4:15:43<3:21:42,  1.26s/it]10/26/2019 12:19:39 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 12:19:39 - INFO - __main__ -     global_step = 2600\n","10/26/2019 12:19:39 - INFO - __main__ -     train loss = 0.0119\n","10/26/2019 12:19:39 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 12:19:39 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 12:19:39 - INFO - __main__ -     Batch size = 64\n","10/26/2019 12:21:13 - INFO - __main__ -     eval_F1 = 0.9459196365799578\n","10/26/2019 12:21:13 - INFO - __main__ -     eval_loss = 0.13985997717827559\n","10/26/2019 12:21:13 - INFO - __main__ -     global_step = 2600\n","10/26/2019 12:21:13 - INFO - __main__ -     loss = 0.0119\n","================================================================================\n","loss 0.0062:  54% 10799/20000 [4:25:31<3:14:22,  1.27s/it]10/26/2019 12:29:27 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 12:29:27 - INFO - __main__ -     global_step = 2700\n","10/26/2019 12:29:27 - INFO - __main__ -     train loss = 0.0062\n","10/26/2019 12:29:27 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 12:29:27 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 12:29:27 - INFO - __main__ -     Batch size = 64\n","10/26/2019 12:31:01 - INFO - __main__ -     eval_F1 = 0.9456431076397676\n","10/26/2019 12:31:01 - INFO - __main__ -     eval_loss = 0.14817580982344225\n","10/26/2019 12:31:01 - INFO - __main__ -     global_step = 2700\n","10/26/2019 12:31:01 - INFO - __main__ -     loss = 0.0062\n","================================================================================\n","loss 0.0035:  56% 11199/20000 [4:35:20<3:05:48,  1.27s/it]10/26/2019 12:39:16 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 12:39:16 - INFO - __main__ -     global_step = 2800\n","10/26/2019 12:39:16 - INFO - __main__ -     train loss = 0.0035\n","10/26/2019 12:39:16 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 12:39:16 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 12:39:16 - INFO - __main__ -     Batch size = 64\n","10/26/2019 12:40:50 - INFO - __main__ -     eval_F1 = 0.9539467624574007\n","10/26/2019 12:40:50 - INFO - __main__ -     eval_loss = 0.16389107977738604\n","10/26/2019 12:40:50 - INFO - __main__ -     global_step = 2800\n","10/26/2019 12:40:50 - INFO - __main__ -     loss = 0.0035\n","================================================================================\n","loss 0.0096:  58% 11599/20000 [4:45:09<2:56:57,  1.26s/it]10/26/2019 12:49:05 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 12:49:05 - INFO - __main__ -     global_step = 2900\n","10/26/2019 12:49:05 - INFO - __main__ -     train loss = 0.0096\n","10/26/2019 12:49:05 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 12:49:05 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 12:49:05 - INFO - __main__ -     Batch size = 64\n","10/26/2019 12:50:39 - INFO - __main__ -     eval_F1 = 0.9441964285714286\n","10/26/2019 12:50:39 - INFO - __main__ -     eval_loss = 0.1635169771616347\n","10/26/2019 12:50:39 - INFO - __main__ -     global_step = 2900\n","10/26/2019 12:50:39 - INFO - __main__ -     loss = 0.0096\n","================================================================================\n","loss 0.0063:  60% 11999/20000 [4:54:57<2:49:22,  1.27s/it]10/26/2019 12:58:53 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 12:58:53 - INFO - __main__ -     global_step = 3000\n","10/26/2019 12:58:53 - INFO - __main__ -     train loss = 0.0063\n","10/26/2019 12:58:54 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 12:58:54 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 12:58:54 - INFO - __main__ -     Batch size = 64\n","10/26/2019 13:00:28 - INFO - __main__ -     eval_F1 = 0.9528990626913475\n","10/26/2019 13:00:28 - INFO - __main__ -     eval_loss = 0.14082356338622048\n","10/26/2019 13:00:28 - INFO - __main__ -     global_step = 3000\n","10/26/2019 13:00:28 - INFO - __main__ -     loss = 0.0063\n","================================================================================\n","loss 0.0053:  62% 12399/20000 [5:04:46<2:40:21,  1.27s/it]10/26/2019 13:08:42 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 13:08:42 - INFO - __main__ -     global_step = 3100\n","10/26/2019 13:08:42 - INFO - __main__ -     train loss = 0.0053\n","10/26/2019 13:08:42 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 13:08:42 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 13:08:42 - INFO - __main__ -     Batch size = 64\n","10/26/2019 13:10:16 - INFO - __main__ -     eval_F1 = 0.9387708526993704\n","10/26/2019 13:10:16 - INFO - __main__ -     eval_loss = 0.1710382507299073\n","10/26/2019 13:10:16 - INFO - __main__ -     global_step = 3100\n","10/26/2019 13:10:16 - INFO - __main__ -     loss = 0.0053\n","================================================================================\n","loss 0.0058:  64% 12799/20000 [5:14:37<2:32:53,  1.27s/it]10/26/2019 13:18:33 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 13:18:33 - INFO - __main__ -     global_step = 3200\n","10/26/2019 13:18:33 - INFO - __main__ -     train loss = 0.0058\n","10/26/2019 13:18:33 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 13:18:33 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 13:18:33 - INFO - __main__ -     Batch size = 64\n","10/26/2019 13:20:08 - INFO - __main__ -     eval_F1 = 0.9330242796037209\n","10/26/2019 13:20:08 - INFO - __main__ -     eval_loss = 0.1587143994984217\n","10/26/2019 13:20:08 - INFO - __main__ -     global_step = 3200\n","10/26/2019 13:20:08 - INFO - __main__ -     loss = 0.0058\n","================================================================================\n","loss 0.0035:  66% 13199/20000 [5:24:31<2:24:16,  1.27s/it]10/26/2019 13:28:27 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 13:28:27 - INFO - __main__ -     global_step = 3300\n","10/26/2019 13:28:27 - INFO - __main__ -     train loss = 0.0035\n","10/26/2019 13:28:27 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 13:28:27 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 13:28:27 - INFO - __main__ -     Batch size = 64\n","10/26/2019 13:30:01 - INFO - __main__ -     eval_F1 = 0.9491309877066554\n","10/26/2019 13:30:01 - INFO - __main__ -     eval_loss = 0.15905056707561016\n","10/26/2019 13:30:01 - INFO - __main__ -     global_step = 3300\n","10/26/2019 13:30:01 - INFO - __main__ -     loss = 0.0035\n","================================================================================\n","loss 0.0026:  68% 13599/20000 [5:34:24<2:16:10,  1.28s/it]10/26/2019 13:38:20 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 13:38:20 - INFO - __main__ -     global_step = 3400\n","10/26/2019 13:38:20 - INFO - __main__ -     train loss = 0.0026\n","10/26/2019 13:38:20 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 13:38:20 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 13:38:20 - INFO - __main__ -     Batch size = 64\n","10/26/2019 13:39:55 - INFO - __main__ -     eval_F1 = 0.9456431076397676\n","10/26/2019 13:39:55 - INFO - __main__ -     eval_loss = 0.17516913829604164\n","10/26/2019 13:39:55 - INFO - __main__ -     global_step = 3400\n","10/26/2019 13:39:55 - INFO - __main__ -     loss = 0.0026\n","================================================================================\n","loss 0.0004:  70% 13999/20000 [5:44:18<2:07:44,  1.28s/it]10/26/2019 13:48:14 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 13:48:14 - INFO - __main__ -     global_step = 3500\n","10/26/2019 13:48:14 - INFO - __main__ -     train loss = 0.0004\n","10/26/2019 13:48:14 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 13:48:14 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 13:48:14 - INFO - __main__ -     Batch size = 64\n","10/26/2019 13:49:48 - INFO - __main__ -     eval_F1 = 0.9387708526993704\n","10/26/2019 13:49:48 - INFO - __main__ -     eval_loss = 0.19492389808874577\n","10/26/2019 13:49:48 - INFO - __main__ -     global_step = 3500\n","10/26/2019 13:49:48 - INFO - __main__ -     loss = 0.0004\n","================================================================================\n","loss 0.003:  72% 14399/20000 [5:54:11<1:59:05,  1.28s/it]10/26/2019 13:58:07 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 13:58:07 - INFO - __main__ -     global_step = 3600\n","10/26/2019 13:58:07 - INFO - __main__ -     train loss = 0.003\n","10/26/2019 13:58:07 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 13:58:07 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 13:58:07 - INFO - __main__ -     Batch size = 64\n","10/26/2019 13:59:42 - INFO - __main__ -     eval_F1 = 0.9459196365799578\n","10/26/2019 13:59:42 - INFO - __main__ -     eval_loss = 0.16013130929786712\n","10/26/2019 13:59:42 - INFO - __main__ -     global_step = 3600\n","10/26/2019 13:59:42 - INFO - __main__ -     loss = 0.003\n","================================================================================\n","loss 0.0072:  74% 14799/20000 [6:04:05<1:50:29,  1.27s/it]10/26/2019 14:08:00 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 14:08:00 - INFO - __main__ -     global_step = 3700\n","10/26/2019 14:08:00 - INFO - __main__ -     train loss = 0.0072\n","10/26/2019 14:08:01 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 14:08:01 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 14:08:01 - INFO - __main__ -     Batch size = 64\n","10/26/2019 14:09:35 - INFO - __main__ -     eval_F1 = 0.9476514182726463\n","10/26/2019 14:09:35 - INFO - __main__ -     eval_loss = 0.15157191827893257\n","10/26/2019 14:09:35 - INFO - __main__ -     global_step = 3700\n","10/26/2019 14:09:35 - INFO - __main__ -     loss = 0.0072\n","================================================================================\n","loss 0.0026:  76% 15199/20000 [6:13:58<1:42:25,  1.28s/it]10/26/2019 14:17:54 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 14:17:54 - INFO - __main__ -     global_step = 3800\n","10/26/2019 14:17:54 - INFO - __main__ -     train loss = 0.0026\n","10/26/2019 14:17:54 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 14:17:54 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 14:17:54 - INFO - __main__ -     Batch size = 64\n","10/26/2019 14:19:28 - INFO - __main__ -     eval_F1 = 0.9441964285714286\n","10/26/2019 14:19:28 - INFO - __main__ -     eval_loss = 0.16397834126837552\n","10/26/2019 14:19:28 - INFO - __main__ -     global_step = 3800\n","10/26/2019 14:19:28 - INFO - __main__ -     loss = 0.0026\n","================================================================================\n","loss 0.0029:  78% 15599/20000 [6:23:51<1:33:35,  1.28s/it]10/26/2019 14:27:46 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 14:27:46 - INFO - __main__ -     global_step = 3900\n","10/26/2019 14:27:46 - INFO - __main__ -     train loss = 0.0029\n","10/26/2019 14:27:47 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 14:27:47 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 14:27:47 - INFO - __main__ -     Batch size = 64\n","10/26/2019 14:29:21 - INFO - __main__ -     eval_F1 = 0.9410707445711424\n","10/26/2019 14:29:21 - INFO - __main__ -     eval_loss = 0.15843971550930291\n","10/26/2019 14:29:21 - INFO - __main__ -     global_step = 3900\n","10/26/2019 14:29:21 - INFO - __main__ -     loss = 0.0029\n","================================================================================\n","loss 0.0011:  80% 15999/20000 [6:33:44<1:24:55,  1.27s/it]10/26/2019 14:37:40 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 14:37:40 - INFO - __main__ -     global_step = 4000\n","10/26/2019 14:37:40 - INFO - __main__ -     train loss = 0.0011\n","10/26/2019 14:37:40 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 14:37:40 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 14:37:40 - INFO - __main__ -     Batch size = 64\n","10/26/2019 14:39:14 - INFO - __main__ -     eval_F1 = 0.9456431076397676\n","10/26/2019 14:39:14 - INFO - __main__ -     eval_loss = 0.17705012764781713\n","10/26/2019 14:39:14 - INFO - __main__ -     global_step = 4000\n","10/26/2019 14:39:14 - INFO - __main__ -     loss = 0.0011\n","================================================================================\n","loss 0.0002:  82% 16399/20000 [6:43:37<1:16:18,  1.27s/it]10/26/2019 14:47:33 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 14:47:33 - INFO - __main__ -     global_step = 4100\n","10/26/2019 14:47:33 - INFO - __main__ -     train loss = 0.0002\n","10/26/2019 14:47:33 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 14:47:33 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 14:47:33 - INFO - __main__ -     Batch size = 64\n","10/26/2019 14:49:07 - INFO - __main__ -     eval_F1 = 0.9459196365799578\n","10/26/2019 14:49:07 - INFO - __main__ -     eval_loss = 0.19939148740377277\n","10/26/2019 14:49:07 - INFO - __main__ -     global_step = 4100\n","10/26/2019 14:49:07 - INFO - __main__ -     loss = 0.0002\n","================================================================================\n","loss 0.0003:  84% 16799/20000 [6:53:30<1:08:07,  1.28s/it]10/26/2019 14:57:25 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 14:57:25 - INFO - __main__ -     global_step = 4200\n","10/26/2019 14:57:25 - INFO - __main__ -     train loss = 0.0003\n","10/26/2019 14:57:26 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 14:57:26 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 14:57:26 - INFO - __main__ -     Batch size = 64\n","10/26/2019 14:59:00 - INFO - __main__ -     eval_F1 = 0.9577845322526173\n","10/26/2019 14:59:00 - INFO - __main__ -     eval_loss = 0.17275061167310923\n","10/26/2019 14:59:00 - INFO - __main__ -     global_step = 4200\n","10/26/2019 14:59:00 - INFO - __main__ -     loss = 0.0003\n","================================================================================\n","loss 0.0001:  86% 17199/20000 [7:03:23<59:34,  1.28s/it]10/26/2019 15:07:19 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 15:07:19 - INFO - __main__ -     global_step = 4300\n","10/26/2019 15:07:19 - INFO - __main__ -     train loss = 0.0001\n","10/26/2019 15:07:19 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 15:07:19 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 15:07:19 - INFO - __main__ -     Batch size = 64\n","10/26/2019 15:08:53 - INFO - __main__ -     eval_F1 = 0.9491309877066554\n","10/26/2019 15:08:53 - INFO - __main__ -     eval_loss = 0.19150223431643099\n","10/26/2019 15:08:53 - INFO - __main__ -     global_step = 4300\n","10/26/2019 15:08:53 - INFO - __main__ -     loss = 0.0001\n","================================================================================\n","loss 0.0001:  88% 17599/20000 [7:13:16<51:50,  1.30s/it]10/26/2019 15:17:12 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 15:17:12 - INFO - __main__ -     global_step = 4400\n","10/26/2019 15:17:12 - INFO - __main__ -     train loss = 0.0001\n","10/26/2019 15:17:13 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 15:17:13 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 15:17:13 - INFO - __main__ -     Batch size = 64\n","10/26/2019 15:18:47 - INFO - __main__ -     eval_F1 = 0.9459196365799578\n","10/26/2019 15:18:47 - INFO - __main__ -     eval_loss = 0.20609708048868924\n","10/26/2019 15:18:47 - INFO - __main__ -     global_step = 4400\n","10/26/2019 15:18:47 - INFO - __main__ -     loss = 0.0001\n","================================================================================\n","loss 0.0031:  90% 17999/20000 [7:23:09<42:27,  1.27s/it]10/26/2019 15:27:05 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 15:27:05 - INFO - __main__ -     global_step = 4500\n","10/26/2019 15:27:05 - INFO - __main__ -     train loss = 0.0031\n","10/26/2019 15:27:06 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 15:27:06 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 15:27:06 - INFO - __main__ -     Batch size = 64\n","10/26/2019 15:28:40 - INFO - __main__ -     eval_F1 = 0.9528990626913475\n","10/26/2019 15:28:40 - INFO - __main__ -     eval_loss = 0.15434878692030907\n","10/26/2019 15:28:40 - INFO - __main__ -     global_step = 4500\n","10/26/2019 15:28:40 - INFO - __main__ -     loss = 0.0031\n","================================================================================\n","loss 0.0083:  92% 18399/20000 [7:33:03<34:00,  1.27s/it]10/26/2019 15:36:59 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 15:36:59 - INFO - __main__ -     global_step = 4600\n","10/26/2019 15:36:59 - INFO - __main__ -     train loss = 0.0083\n","10/26/2019 15:36:59 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 15:36:59 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 15:36:59 - INFO - __main__ -     Batch size = 64\n","10/26/2019 15:38:33 - INFO - __main__ -     eval_F1 = 0.9582270020658648\n","10/26/2019 15:38:33 - INFO - __main__ -     eval_loss = 0.12482789444038644\n","10/26/2019 15:38:33 - INFO - __main__ -     global_step = 4600\n","10/26/2019 15:38:33 - INFO - __main__ -     loss = 0.0083\n","================================================================================\n","loss 0.0024:  94% 18799/20000 [7:42:57<25:37,  1.28s/it]10/26/2019 15:46:53 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 15:46:53 - INFO - __main__ -     global_step = 4700\n","10/26/2019 15:46:53 - INFO - __main__ -     train loss = 0.0024\n","10/26/2019 15:46:53 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 15:46:53 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 15:46:53 - INFO - __main__ -     Batch size = 64\n","10/26/2019 15:48:28 - INFO - __main__ -     eval_F1 = 0.9528990626913475\n","10/26/2019 15:48:28 - INFO - __main__ -     eval_loss = 0.172564608277753\n","10/26/2019 15:48:28 - INFO - __main__ -     global_step = 4700\n","10/26/2019 15:48:28 - INFO - __main__ -     loss = 0.0024\n","================================================================================\n","loss 0.0048:  96% 19199/20000 [7:52:51<17:03,  1.28s/it]10/26/2019 15:56:47 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 15:56:47 - INFO - __main__ -     global_step = 4800\n","10/26/2019 15:56:47 - INFO - __main__ -     train loss = 0.0048\n","10/26/2019 15:56:48 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 15:56:48 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 15:56:48 - INFO - __main__ -     Batch size = 64\n","10/26/2019 15:58:22 - INFO - __main__ -     eval_F1 = 0.9564419513248275\n","10/26/2019 15:58:22 - INFO - __main__ -     eval_loss = 0.16457295324653387\n","10/26/2019 15:58:22 - INFO - __main__ -     global_step = 4800\n","10/26/2019 15:58:22 - INFO - __main__ -     loss = 0.0048\n","================================================================================\n","loss 0.0041:  98% 19599/20000 [8:02:46<08:32,  1.28s/it]10/26/2019 16:06:42 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 16:06:42 - INFO - __main__ -     global_step = 4900\n","10/26/2019 16:06:42 - INFO - __main__ -     train loss = 0.0041\n","10/26/2019 16:06:42 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 16:06:42 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 16:06:42 - INFO - __main__ -     Batch size = 64\n","10/26/2019 16:08:16 - INFO - __main__ -     eval_F1 = 0.9562137454571761\n","10/26/2019 16:08:16 - INFO - __main__ -     eval_loss = 0.14650616538710892\n","10/26/2019 16:08:16 - INFO - __main__ -     global_step = 4900\n","10/26/2019 16:08:16 - INFO - __main__ -     loss = 0.0041\n","================================================================================\n","loss 0.0015: 100% 19999/20000 [8:12:40<00:01,  1.28s/it]10/26/2019 16:16:36 - INFO - __main__ -   ***** Report result *****\n","10/26/2019 16:16:36 - INFO - __main__ -     global_step = 5000\n","10/26/2019 16:16:36 - INFO - __main__ -     train loss = 0.0015\n","10/26/2019 16:16:36 - INFO - __main__ -   ***** Running evaluation *****\n","10/26/2019 16:16:36 - INFO - __main__ -     Num examples = 1000\n","10/26/2019 16:16:36 - INFO - __main__ -     Batch size = 64\n","10/26/2019 16:18:11 - INFO - __main__ -     eval_F1 = 0.9559824618817688\n","10/26/2019 16:18:11 - INFO - __main__ -     eval_loss = 0.1705873376922682\n","10/26/2019 16:18:11 - INFO - __main__ -     global_step = 5000\n","10/26/2019 16:18:11 - INFO - __main__ -     loss = 0.0015\n","================================================================================\n","loss 0.0015: 100% 20000/20000 [8:14:16<00:00, 29.68s/it]\n","10/26/2019 16:18:11 - INFO - pytorch_transformers.modeling_utils -   loading weights file ./model_roberta/pytorch_model.bin\n","dev 0.9654600718430506\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n","  'recall', 'true', average, warn_for)\n","test 0.46294307196562834\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RxKY6NrhzhvJ","colab_type":"code","colab":{}},"source":["!python combine.py --model_prefix ./model_roberta --out_path ./result/result_6.csv"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OcEOGJfN6Fu5","colab_type":"text"},"source":[""]}]}